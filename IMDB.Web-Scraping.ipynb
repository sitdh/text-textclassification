{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./img/homepage.png\" style=\"max-height: 400px; max-width: auto;\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load web-scraping.py\n",
    "import requests, logging\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "\n",
    "def counting_movie_entity(content):\n",
    "\n",
    "  soup = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "  content = soup.find('div', id='content-2-wide')\n",
    "  description = content.find('div', class_='desc')\n",
    "\n",
    "  counting, entity = description.find('span').text.split(' of ')\n",
    "\n",
    "  counting = int(counting.split('-')[-1].strip().replace(',', ''))\n",
    "  entity = int(entity.replace(',', '').replace('titles.', '').strip())\n",
    "\n",
    "  return counting, entity\n",
    "\n",
    "def extract_movie_title(title_list):\n",
    "  soup = BeautifulSoup(title_list, 'html.parser')\n",
    "\n",
    "  movie_titles = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "\n",
    "  movie_extract = []\n",
    "\n",
    "  for movie_title in movie_titles:\n",
    "    _, title, year = movie_title.find('h3', class_='lister-item-header').text.strip().split(\"\\n\")\n",
    "\n",
    "    year = year.replace(')', '').replace('(', '').split(' ')[-1]\n",
    "    year = year.split('–')[-1] if '–' in year else year\n",
    "    year = int(year)\n",
    "\n",
    "    run_time_minute = int(movie_title.find('span', class_='runtime').text.replace('min', '').strip())\n",
    "    movie_genre = movie_title.find('span', class_='genre').text.strip()\n",
    "\n",
    "    movie_rate = None\n",
    "    try:\n",
    "      movie_rate = movie_title.find('span', class_='certificate').text.strip()\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    movie_rating = float(movie_title.find('div', class_='ratings-bar').text.strip().split(\"\\n\")[0])\n",
    "\n",
    "    meta_score = 0\n",
    "    try:\n",
    "      meta_score = int(movie_title.find('span', class_='metascore favorable').text.strip())\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    movie_desc = movie_title.find_all('p', class_='text-muted')[-1].text.strip()\n",
    "\n",
    "    directors, starts = [m.strip() for m in movie_title.find('p', class_='').text.strip().split('Stars:')]\n",
    "    if 'Director:' in directors:\n",
    "      directors = directors.replace('Director:', '').replace('|', '').strip()\n",
    "    else:\n",
    "      directors = '+'.join(s.strip() for s in directors.replace('Directors:', '').replace('|', '').strip().split(','))\n",
    "\n",
    "    directors = directors.strip() if len(directors) else None\n",
    "\n",
    "    starts = '+'.join(s.strip() for s in starts.replace(\" \\n\", '').split(','))\n",
    "\n",
    "    movie_vote_gross = movie_title.find('p', class_='sort-num_votes-visible').text.strip().split(\"\\n\")\n",
    "    movie_vote = movie_vote_gross[1]\n",
    "    movie_gross = movie_vote_gross[-1] if len(movie_vote_gross) > 2 else None \n",
    "\n",
    "    movie_vote = int(movie_vote.replace(',', ''))\n",
    "\n",
    "    movie_extract.append({\n",
    "      'title': title,\n",
    "      'year': year,\n",
    "      'movie_rate': movie_rate,\n",
    "      'runtime': run_time_minute,\n",
    "      'genre': movie_genre,\n",
    "      'rating': movie_rating,\n",
    "      'metascore': meta_score,\n",
    "      'description': movie_desc,\n",
    "      'directors': directors,\n",
    "      'starts': starts,\n",
    "      'vote': movie_vote,\n",
    "      'gross': movie_gross,\n",
    "    })\n",
    "\n",
    "  return movie_extract\n",
    "\n",
    "def store_data(movie_list, corpus_location=\"movie_corpus.csv\", sep=\"|\"):\n",
    "  import csv\n",
    "\n",
    "  movie = movie_list[-1]\n",
    "  movie_keys = list(movie.keys())\n",
    "\n",
    "  print('Open file', corpus_location, end=' ')\n",
    "\n",
    "  with open(corpus_location, 'w') as f:\n",
    "    writer = csv.DictWriter(\n",
    "      f,\n",
    "      fieldnames=movie_keys,\n",
    "      delimiter=sep,\n",
    "      dialect=csv.unix_dialect\n",
    "    )\n",
    "\n",
    "    try:\n",
    "      writer.writeheader()\n",
    "      writer.writerows(movie_list)\n",
    "      print('Data wrote')\n",
    "    except:\n",
    "      print('Fail')\n",
    "      corpus_location = None\n",
    "\n",
    "  return corpus_location\n",
    "\n",
    "def start_scrape():\n",
    "  import math, time, random\n",
    "\n",
    "  url_template = url_template = \"https://www.imdb.com/search/title/?release_date=2010&sort=num_votes,desc&page={page_number}\"\n",
    "  imdb_url = url_template.format(page_number=1)\n",
    "  response = requests.get(imdb_url)\n",
    "\n",
    "  response_text = response.text\n",
    "\n",
    "  title_per_page, title_count = counting_movie_entity(response_text)\n",
    "\n",
    "  page_range = math.ceil(title_count / title_per_page)\n",
    "  print(\"Number of page\", page_range, \"All title\", title_count)\n",
    "\n",
    "  movie_store = []\n",
    "\n",
    "  error_pages = []\n",
    "  for i in range(1, page_range+1):\n",
    "\n",
    "    print('Executing page number', i, end=\" \")\n",
    "\n",
    "    try:\n",
    "      imdb_url = url_template.format(page_number=i)\n",
    "      response = requests.get(imdb_url)\n",
    "      response_text = response.text\n",
    "\n",
    "      movie_store += extract_movie_title(response_text)\n",
    "\n",
    "      print('Done')\n",
    "    except:\n",
    "      print('Error')\n",
    "      error_pages.append(i)\n",
    "\n",
    "    waiting = random.randint(0, 3) + random.random()\n",
    "    print(f\"Waiting for\", waiting, 'sec.')\n",
    "    time.sleep(waiting)\n",
    "\n",
    "  if len(error_pages):\n",
    "    print('Error pages:', ', '.join(error_pages))\n",
    "\n",
    "  return movie_store\n",
    "\n",
    "if '__main__' == __name__:\n",
    "  movie_copus = start_scrape()\n",
    "  file_name = store_data(movie_copus)\n",
    "  print(\"Done\", file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextClassification",
   "language": "python",
   "name": "textclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
