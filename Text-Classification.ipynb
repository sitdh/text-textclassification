{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification with IMDB Movie's description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./img/homepage.png\" style=\"max-height: 400px; max-width: auto;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information please open "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv, re, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file = 'movie_corpus.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_reduced = lambda x: x if None != x and len(str(x)) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "with open(corpus_file) as f:\n",
    "    movie_corpus_reader = csv.DictReader(f, delimiter='|')\n",
    "    fields = movie_corpus_reader.fieldnames\n",
    "    \n",
    "    for movie in movie_corpus_reader:\n",
    "        if movie['genre'] in (\"\", None) or 0 == len(movie['genre']):\n",
    "            continue\n",
    "            \n",
    "        if movie['description'] in ('', None) or 0 == len(movie['description']):\n",
    "            continue\n",
    "            \n",
    "        movie['year'] = str(movie['year']) if str(movie['year']).isnumeric() and 4 == len(str(movie['year'])) else None\n",
    "        movie = {k: value_reduced(v) for k,v in movie.items() if 'metascore' != k}\n",
    "        dataset.append(movie)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_seed = int(random.random() * 1e+10)\n",
    "random_seed = 2958053999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(\n",
    "    dataset,\n",
    "    random_state=random_seed,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "stratisfy_train = {'title': [m['title'] for m in train_dataset]}\n",
    "stratisfy_train['genre'] = [m['genre'] for m in train_dataset]\n",
    "\n",
    "stratisfy_test = {'title': [m['title'] for m in test_dataset]}\n",
    "stratisfy_test['genre'] = [m['genre'] for m in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Snabba cash II',\n",
       " 'year': '2012',\n",
       " 'movie_rate': None,\n",
       " 'runtime': '99',\n",
       " 'genre': 'Action, Crime, Drama',\n",
       " 'rating': '6.3',\n",
       " 'description': 'Three years later, JW gets out of prison, but soon finds himself between the contending parties of his criminal past.',\n",
       " 'directors': 'Babak Najafi+Bruce Axl Argeadson',\n",
       " 'starts': 'Joel Kinnaman+Matias Varela+Dragomir Mrsic+Fares Fares'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(train_dataset)\n",
    "y_train = pd.DataFrame(stratisfy_train)\n",
    "\n",
    "X_test = pd.DataFrame(test_dataset)\n",
    "y_test = pd.DataFrame(stratisfy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_corpus[['genre']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract movie's genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "movie_extract_func"
    ]
   },
   "outputs": [],
   "source": [
    "def movie_genre_extraction(corpus):\n",
    "\n",
    "    movie_genre = sorted(list(set([genre.strip() \n",
    "                  for genres in corpus[~corpus.genre.isna()]['genre'].tolist()\n",
    "                  for genre in genres.split(', ')])))\n",
    "    \n",
    "    return [k for k in movie_genre if len(k)]\n",
    "\n",
    "def update_for_genre(genre, corpus):\n",
    "    for genre in movie_genre:\n",
    "        corpus[genre] = corpus[~corpus.isna()]['genre'].apply(\n",
    "            lambda x: 1 if 'str' == type(x).__name__ and genre in x else 0\n",
    "        )\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "def text_to_float(g):\n",
    "    \n",
    "    gross = 0\n",
    "\n",
    "    if 'float' == type(g).__name__:\n",
    "        gross = g\n",
    "        print(gross)\n",
    "    else:\n",
    "        gross = float(g.lower().replace('$', '').replace('m', ''))\n",
    "        \n",
    "    return gross\n",
    "\n",
    "def covert_gross(corpus):\n",
    "    return corpus['gross'][~corpus['gross'].isnull()].apply(text_to_float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert movie genre to one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adult</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Biography</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Family</th>\n",
       "      <th>...</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>News</th>\n",
       "      <th>Reality-TV</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Talk-Show</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Padre no hay más que uno</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marvin ou la belle éducation</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Snabba cash II</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Save Yourself</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anoko wa kizoku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          title  Action  Adult  Adventure  Animation  \\\n",
       "0      Padre no hay más que uno       0      0          0          0   \n",
       "1  Marvin ou la belle éducation       0      0          0          0   \n",
       "2                Snabba cash II       1      0          0          0   \n",
       "3                 Save Yourself       0      0          0          0   \n",
       "4               Anoko wa kizoku       0      0          0          0   \n",
       "\n",
       "   Biography  Comedy  Crime  Drama  Family  ...  Mystery  News  Reality-TV  \\\n",
       "0          0       1      0      0       1  ...        0     0           0   \n",
       "1          0       0      0      1       0  ...        0     0           0   \n",
       "2          0       0      1      1       0  ...        0     0           0   \n",
       "3          0       1      0      1       0  ...        0     0           0   \n",
       "4          0       0      0      1       0  ...        0     0           0   \n",
       "\n",
       "   Romance  Sci-Fi  Sport  Talk-Show  Thriller  War  Western  \n",
       "0        0       0      0          0         0    0        0  \n",
       "1        0       0      0          0         0    0        0  \n",
       "2        0       0      0          0         0    0        0  \n",
       "3        1       0      0          0         0    0        0  \n",
       "4        0       0      0          0         0    0        0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_genre = movie_genre_extraction(y_train)\n",
    "for genre in train_genre:\n",
    "    y_train[genre] = y_train.genre.apply(\n",
    "        lambda x: 1 if genre in x else 0\n",
    "    )\n",
    "    \n",
    "del y_train['genre']\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split out title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_train = X_train[['title', 'description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download stopwords (Required at first run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialog below will be shown after cell aboved was executed. All downloaded resource store in `~/nltk_data`\n",
    "\n",
    "<center><img src=\"./img/nltk-package.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./img/nltk-package-downloaded.png\" /></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: We need to tokenized movies description we collected from IMDB with task\n",
    "\n",
    "- [ ] Remove all special characters such as `,`, `.` or `;` even numbers from description\n",
    "- [ ] Tokenize movie description\n",
    "- [ ] Count tokens' frequency\n",
    "- [ ] Convert to lower characters\n",
    "- [ ] Remove stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = re.sub('[^A-Za-z ]+', '', movie_corpus.description[0].lower())\n",
    "sentence = movie_corpus.description[0].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "movie_corpus.description[0]\n",
    "sentence = movie_corpus.description[0].lower()\n",
    "\n",
    "tokenized = word_tokenize(sentence)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = frozenset(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_set = set(tokenized)\n",
    "\n",
    "remaining = tokenized_set - english_stopwords\n",
    "remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = Counter(remaining)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classification(object):\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        \n",
    "    def __call__(self):\n",
    "        self.f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenize(description) -> str:\n",
    "    import re\n",
    "    return re.sub('[^A-Za-z ]+', '', description.lower())\n",
    "\n",
    "def counting(description, stopwords=None):\n",
    "    if None == stopwords:\n",
    "        from nltk import stopwords\n",
    "        stopwords = frozenset(stopwords.words('english'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TextClassification",
   "language": "python",
   "name": "textclassification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
